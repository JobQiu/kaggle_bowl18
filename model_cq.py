import os
import sys
import glob
import random
import math
import datetime
import itertools
import json
import re
import logging
from collections import OrderedDict
import numpy as np
import scipy.misc
import tensorflow as tf
import keras
import keras.backend as K
import keras.layers as KL
import keras.initializers as KI
import keras.engine as KE
import keras.models as KM

import utils

# Requires TensorFlow 1.3+ and Keras 2.0.8+.
from distutils.version import LooseVersion

assert LooseVersion(tf.__version__) >= LooseVersion("1.3")
assert LooseVersion(keras.__version__) >= LooseVersion('2.0.8')


class MaskRCNN():

    def __init__(self, mode, config, model_dir):
        assert mode in ['training', 'inference']
        self.mode = mode
        self.config = config
        self.model_dir = model_dir
        self.set_log_dir()
        self.keras_model = self.build(mode=mode, config=config)

    def build(self, mode, config):
        # 1. check the size can be divide by 0 for at least several times
        h, w = config.IMAGE_SHAPE[:2]
        if h/ 2**6 != int(h/2**6) or w/ 2**6 != int(w/2**6):
            raise Exception("lalala")

        input_image = KL.Input(shape=config.IMAGE_SHAPE.tolist(), name = 'input_image')
        input_image_meta = KL.Input(shape = [None], name= 'input_image_meta')
        # TODO:  what odes meta for ?

        if mode == 'training':

            # RPN GT
            input_rpn_match = KL.Input(
                shape=[None, 1], name="input_rpn_match", dtype=tf.int32)
            input_rpn_bbox = KL.Input(
                shape=[None, 4], name="input_rpn_bbox", dtype=tf.float32)

            # Detection GT (class IDs, bounding boxes, and masks)
            # 1. GT Class IDs (zero padded)
            input_gt_class_ids = KL.Input(
                shape=[None], name="input_gt_class_ids", dtype=tf.int32)
            # 2. GT Boxes in pixels (zero padded)
            # [batch, MAX_GT_INSTANCES, (y1, x1, y2, x2)] in image coordinates
            input_gt_boxes = KL.Input(
                shape=[None, 4], name="input_gt_boxes", dtype=tf.float32)
            #normalize the coordinates

            # what does this mean.
            h, w = K.shape(input_image)[0], K.shape(input_image)[1]
            _, C2, C3, C4, C5 = resnet_graph(input_image, config.RESNET_ARCHITECTURE, stage5 = True)
            # TODO: add assert to varify feature map sizes match what's in config
            P5 = KL.Conv2D(256, (1, 1), name='fpn_c5p5')(C5)
            P4 = KL.Add(name="fpn_p4add")([
                KL.UpSampling2D(size=(2, 2), name="fpn_p5upsampled")(P5),
                KL.Conv2D(256, (1, 1), name='fpn_c4p4')(C4)])
            P3 = KL.Add(name="fpn_p3add")([
                KL.UpSampling2D(size=(2, 2), name="fpn_p4upsampled")(P4),
                KL.Conv2D(256, (1, 1), name='fpn_c3p3')(C3)])
            P2 = KL.Add(name="fpn_p2add")([
                KL.UpSampling2D(size=(2, 2), name="fpn_p3upsampled")(P3),
                KL.Conv2D(256, (1, 1), name='fpn_c2p2')(C2)])
            # Attach 3x3 conv to all P layers to get the final feature maps.
            P2 = KL.Conv2D(256, (3, 3), padding="SAME", name="fpn_p2")(P2)
            P3 = KL.Conv2D(256, (3, 3), padding="SAME", name="fpn_p3")(P3)
            P4 = KL.Conv2D(256, (3, 3), padding="SAME", name="fpn_p4")(P4)
            P5 = KL.Conv2D(256, (3, 3), padding="SAME", name="fpn_p5")(P5)
            # P6 is used for the 5th anchor scale in RPN. Generated by
            # subsampling from P5 with stride of 2.
            P6 = KL.MaxPooling2D(pool_size=(1, 1), strides=2, name="fpn_p6")(P5)

            pass
        else:
            pass

            # Generate Anchors
        self.anchors = utils.generate_pyramid_anchors(config.RPN_ANCHOR_SCALES,
                                                      config.RPN_ANCHOR_RATIOS,
                                                      config.BACKBONE_SHAPES,
                                                      config.BACKBONE_STRIDES,
                                                      config.RPN_ANCHOR_STRIDE)
        rpn = build_rpn_model(config.RPN_ANCHOR_STRIDE,
                              len(config.RPN_ANCHOR_RATIOS),
                              256)
        rpn_feature_maps = [P2, P3, P4, P5, P6]
        # why rpn need p6, because p6, the shape is very small, so the size of anchor can be larger?
        mrcnn_feature_maps = [P2, P3, P4, P5]

        layer_outputs= []
        for p in rpn_feature_maps:
            layer_outputs.append(rpn([p]))

        output_names = ["rpn_class_logits", "rpn_class", "rpn_bbox"]
        outputs = list(zip(*layer_outputs))
        outputs = [KL.Concatenate(axis = 1, name = n )(list(o)) for o,n in zip(outputs,output_names)]
        rpn_class_logits, rpn_class, rpn_bbox = outputs

        proposal_count = config.POST_NMS_ROIS_TRAINING if mode == "training"\
            else config.POST_NMS_ROIS_INFERENCE
        rpn_rois = ProposalLayer()

def resnet_graph(input_image, architecture, stage5=False):
    pass


def build_rpn_model(anchor_stride, anchors_per_location, depth):
    pass


class ProposalLayer(KE.Layer):

    def __init__(self, proposal_count, nms_threshold, anchors,
                 config=None, **kwargs):

        super(ProposalLayer, self).__init__(**kwargs)
        self.config = config
        self.proposal_count = proposal_count
        self.nms_threshold = nms_threshold
        self.anchors = anchors.astype(np.float32)

    def call(self, inputs):
        scores = inputs[0][:,:,1] # just the probability for the foreground
        deltas = inputs[1] # all the delta of coresponding
        deltas = deltas * np.reshape(self.config.RPN_BBOX_STD_DEV,[1,1,4])
        anchors = self.anchors

        pre_nms_limit = min(6000, anchors.shape[0])

        # sort the scores and take the first like 2000, and fetch their indicx
        ix = tf.nn.top_k(scores, pre_nms_limit, sorted=True, name='top_anchors').indices
        scores = utils.batch_slice()

class DetectionTargetLayer(KE.Layer):
    def __init__(self, config, **kwargs):
        super(DetectionTargetLayer, self).__init__(**kwargs)
        self.config = config
        pass

    def call(self, inputs, **kwargs):
        proposal = inputs[0]
        gt_class_ids = inputs[1]
        gt_boxes = inputs[2]
        gt_masks = inputs[3]

